{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f34eb49-2334-4189-8d08-b144f9c94f16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d8f585d-eb6b-47ad-b9f2-1e509f829070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Olist ECommerce Performance Optimization\").config('spark.executor.memory','6g').config('spark.executor.cores','4').config('spark.executor.instances','2').config('spark.driver.memory','4g').config('spark.driver.maxResultSize','2g').config('spark.sql.shuffle.partitions','64').config('spark.default.parallelism','64').config('spark.sql.adaptive.enabled','true').config('spark.sql.adaptive.coalescePartition.enabled','true').config('spark.sql.autoBroadcastJoinThreshold',20*1024*1024).config('spark.sql.files.maxPartitionBytes','64MB').config('spark.sql.files.openCostInBytes','2MB').config('spark.memory.fraction',0.8).config('spark.memory.storageFraction',0.2).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c566473b-87c2-49f8-968b-2a0077426e9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read all CSVs into Spark DataFrames\n",
    "df_customers = spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/commerce_spark_workspace/default/ecommerce_raw/olist_customers_dataset.csv\")\n",
    "df_geolocation = spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/commerce_spark_workspace/default/ecommerce_raw/olist_geolocation_dataset.csv\")\n",
    "df_order_items = spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/commerce_spark_workspace/default/ecommerce_raw/olist_order_items_dataset.csv\")\n",
    "df_order_payments = spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/commerce_spark_workspace/default/ecommerce_raw/olist_order_payments_dataset.csv\")\n",
    "df_order_reviews = spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/commerce_spark_workspace/default/ecommerce_raw/olist_order_reviews_dataset.csv\")\n",
    "df_orders = spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/commerce_spark_workspace/default/ecommerce_raw/olist_orders_dataset.csv\")\n",
    "df_products = spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/commerce_spark_workspace/default/ecommerce_raw/olist_products_dataset.csv\")\n",
    "df_sellers = spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/commerce_spark_workspace/default/ecommerce_raw/olist_sellers_dataset.csv\")\n",
    "df_product_category_name_translation = spark.read.option(\"header\", True).csv(\"dbfs:/Volumes/commerce_spark_workspace/default/ecommerce_raw/product_category_name_translation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c5ded2-e50f-44b5-b7df-b7b985baccc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Optimized Join Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7faf580-fd52-44db-8812-6b4bb9ecceb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+--------------------+------------------------+--------------------+--------------+\n|         customer_id|            order_id|order_status|order_purchase_timestamp|  order_approved_at|order_delivered_carrier_date|order_delivered_customer_date|order_estimated_delivery_date|  customer_unique_id|customer_zip_code_prefix|       customer_city|customer_state|\n+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+--------------------+------------------------+--------------------+--------------+\n|9ef432eb625129730...|e481f51cbdc54678b...|   delivered|     2017-10-02 10:56:33|2017-10-02 11:07:15|         2017-10-04 19:55:00|          2017-10-10 21:25:13|          2017-10-18 00:00:00|7c396fd4830fd0422...|                   03149|           sao paulo|            SP|\n|b0830fb4747a6c6d2...|53cdb2fc8bc7dce0b...|   delivered|     2018-07-24 20:41:37|2018-07-26 03:24:27|         2018-07-26 14:31:00|          2018-08-07 15:27:45|          2018-08-13 00:00:00|af07308b275d755c9...|                   47813|           barreiras|            BA|\n|41ce2a54c0b03bf34...|47770eb9100c2d0c4...|   delivered|     2018-08-08 08:38:49|2018-08-08 08:55:23|         2018-08-08 13:50:00|          2018-08-17 18:06:29|          2018-09-04 00:00:00|3a653a41f6f9fc3d2...|                   75265|          vianopolis|            GO|\n|f88197465ea7920ad...|949d5b44dbf5de918...|   delivered|     2017-11-18 19:28:06|2017-11-18 19:45:59|         2017-11-22 13:39:59|          2017-12-02 00:28:42|          2017-12-15 00:00:00|7c142cf63193a1473...|                   59296|sao goncalo do am...|            RN|\n|8ab97904e6daea886...|ad21c59c0840e6cb8...|   delivered|     2018-02-13 21:18:39|2018-02-13 22:20:29|         2018-02-14 19:46:34|          2018-02-16 18:17:02|          2018-02-26 00:00:00|72632f0f9dd73dfee...|                   09195|         santo andre|            SP|\n+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+--------------------+------------------------+--------------------+--------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "#Broadcast join with df_customers and df_orders\n",
    "from pyspark.sql.functions import broadcast, col\n",
    "\n",
    "df_customers = df_customers.withColumn(\"customer_id\", col(\"customer_id\").cast(\"string\"))\n",
    "df_orders = df_orders.withColumn(\"customer_id\", col(\"customer_id\").cast(\"string\"))\n",
    "\n",
    "df_joined = df_orders.join(broadcast(df_customers), on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "df_joined.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26bb438f-0ad6-4003-9eaf-13889bc9636d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+--------------------+-------------------+-----+-------------+---------------------+-------------------+--------------------------+------------------+----------------+-----------------+-----------------+----------------+\n|          product_id|            order_id|order_item_id|           seller_id|shipping_limit_date|price|freight_value|product_category_name|product_name_lenght|product_description_lenght|product_photos_qty|product_weight_g|product_length_cm|product_height_cm|product_width_cm|\n+--------------------+--------------------+-------------+--------------------+-------------------+-----+-------------+---------------------+-------------------+--------------------------+------------------+----------------+-----------------+-----------------+----------------+\n|2b4609f8948be1887...|00bbc417955452474...|            1|cc419e0650a3c5ba7...|2017-08-18 03:15:35|89.99|         7.88|         beleza_saude|                 59|                       492|                 3|             250|               22|               10|              18|\n|2b4609f8948be1887...|022e34b10acb0f74f...|            1|cc419e0650a3c5ba7...|2018-01-22 16:09:04|89.99|        16.39|         beleza_saude|                 59|                       492|                 3|             250|               22|               10|              18|\n|2b4609f8948be1887...|02b73712c7944322d...|            1|cc419e0650a3c5ba7...|2017-09-25 11:03:43|89.99|        14.38|         beleza_saude|                 59|                       492|                 3|             250|               22|               10|              18|\n|2b4609f8948be1887...|03167be79e12e9d70...|            1|cc419e0650a3c5ba7...|2017-12-15 21:50:37|89.99|         9.44|         beleza_saude|                 59|                       492|                 3|             250|               22|               10|              18|\n|2b4609f8948be1887...|03515a836bb855b03...|            1|cc419e0650a3c5ba7...|2018-01-29 13:36:01|89.99|        16.39|         beleza_saude|                 59|                       492|                 3|             250|               22|               10|              18|\n+--------------------+--------------------+-------------+--------------------+-------------------+-----+-------------+---------------------+-------------------+--------------------------+------------------+----------------+-----------------+-----------------+----------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Cast join keys to string\n",
    "df_order_items = df_order_items.withColumn(\"product_id\", col(\"product_id\").cast(\"string\"))\n",
    "df_products = df_products.withColumn(\"product_id\", col(\"product_id\").cast(\"string\"))\n",
    "\n",
    "# Repartition both DataFrames by product_id\n",
    "df_order_items_repart = df_order_items.repartition(\"product_id\")\n",
    "df_products_repart = df_products.repartition(\"product_id\")\n",
    "\n",
    "# Join DataFrames\n",
    "df_joined = df_order_items_repart.join(df_products_repart, on=\"product_id\", how=\"inner\")\n",
    "\n",
    "df_joined.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60f601fe-02fb-4aec-80e5-f040730ec230",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+--------------------+------------------------+--------------------+--------------+\n|         customer_id|            order_id|order_status|order_purchase_timestamp|  order_approved_at|order_delivered_carrier_date|order_delivered_customer_date|order_estimated_delivery_date|  customer_unique_id|customer_zip_code_prefix|       customer_city|customer_state|\n+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+--------------------+------------------------+--------------------+--------------+\n|9ef432eb625129730...|e481f51cbdc54678b...|   delivered|     2017-10-02 10:56:33|2017-10-02 11:07:15|         2017-10-04 19:55:00|          2017-10-10 21:25:13|          2017-10-18 00:00:00|7c396fd4830fd0422...|                   03149|           sao paulo|            SP|\n|b0830fb4747a6c6d2...|53cdb2fc8bc7dce0b...|   delivered|     2018-07-24 20:41:37|2018-07-26 03:24:27|         2018-07-26 14:31:00|          2018-08-07 15:27:45|          2018-08-13 00:00:00|af07308b275d755c9...|                   47813|           barreiras|            BA|\n|41ce2a54c0b03bf34...|47770eb9100c2d0c4...|   delivered|     2018-08-08 08:38:49|2018-08-08 08:55:23|         2018-08-08 13:50:00|          2018-08-17 18:06:29|          2018-09-04 00:00:00|3a653a41f6f9fc3d2...|                   75265|          vianopolis|            GO|\n|f88197465ea7920ad...|949d5b44dbf5de918...|   delivered|     2017-11-18 19:28:06|2017-11-18 19:45:59|         2017-11-22 13:39:59|          2017-12-02 00:28:42|          2017-12-15 00:00:00|7c142cf63193a1473...|                   59296|sao goncalo do am...|            RN|\n|8ab97904e6daea886...|ad21c59c0840e6cb8...|   delivered|     2018-02-13 21:18:39|2018-02-13 22:20:29|         2018-02-14 19:46:34|          2018-02-16 18:17:02|          2018-02-26 00:00:00|72632f0f9dd73dfee...|                   09195|         santo andre|            SP|\n+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+--------------------+------------------------+--------------------+--------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "#Sort And Merge\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Cast join keys to string to avoid type issues\n",
    "df_customers = df_customers.withColumn(\"customer_id\", col(\"customer_id\").cast(\"string\"))\n",
    "df_orders = df_orders.withColumn(\"customer_id\", col(\"customer_id\").cast(\"string\"))\n",
    "\n",
    "# Repartition and sort df_customers by customer_id\n",
    "df_customers_sorted = df_customers.repartition(\"customer_id\").sortWithinPartitions(\"customer_id\")\n",
    "\n",
    "# Join with df_orders (no repartition or sort on df_orders)\n",
    "df_joined = df_orders.join(df_customers_sorted, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "df_joined.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f36289ac-6af7-4db8-bbaf-57fa6b59f195",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+--------------------+------------------------+--------------------+--------------+\n|         customer_id|            order_id|order_status|order_purchase_timestamp|  order_approved_at|order_delivered_carrier_date|order_delivered_customer_date|order_estimated_delivery_date|  customer_unique_id|customer_zip_code_prefix|       customer_city|customer_state|\n+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+--------------------+------------------------+--------------------+--------------+\n|9ef432eb625129730...|e481f51cbdc54678b...|   delivered|     2017-10-02 10:56:33|2017-10-02 11:07:15|         2017-10-04 19:55:00|          2017-10-10 21:25:13|          2017-10-18 00:00:00|7c396fd4830fd0422...|                   03149|           sao paulo|            SP|\n|b0830fb4747a6c6d2...|53cdb2fc8bc7dce0b...|   delivered|     2018-07-24 20:41:37|2018-07-26 03:24:27|         2018-07-26 14:31:00|          2018-08-07 15:27:45|          2018-08-13 00:00:00|af07308b275d755c9...|                   47813|           barreiras|            BA|\n|41ce2a54c0b03bf34...|47770eb9100c2d0c4...|   delivered|     2018-08-08 08:38:49|2018-08-08 08:55:23|         2018-08-08 13:50:00|          2018-08-17 18:06:29|          2018-09-04 00:00:00|3a653a41f6f9fc3d2...|                   75265|          vianopolis|            GO|\n|f88197465ea7920ad...|949d5b44dbf5de918...|   delivered|     2017-11-18 19:28:06|2017-11-18 19:45:59|         2017-11-22 13:39:59|          2017-12-02 00:28:42|          2017-12-15 00:00:00|7c142cf63193a1473...|                   59296|sao goncalo do am...|            RN|\n|8ab97904e6daea886...|ad21c59c0840e6cb8...|   delivered|     2018-02-13 21:18:39|2018-02-13 22:20:29|         2018-02-14 19:46:34|          2018-02-16 18:17:02|          2018-02-26 00:00:00|72632f0f9dd73dfee...|                   09195|         santo andre|            SP|\n+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+--------------------+------------------------+--------------------+--------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "#Bucket Join\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Cast join keys to string\n",
    "df_customers = df_customers.withColumn(\"customer_id\", col(\"customer_id\").cast(\"string\"))\n",
    "df_orders = df_orders.withColumn(\"customer_id\", col(\"customer_id\").cast(\"string\"))\n",
    "\n",
    "# Repartition and sort df_customers on customer_id\n",
    "df_customers_sorted = df_customers.repartition(\"customer_id\").sortWithinPartitions(\"customer_id\")\n",
    "\n",
    "# Join with df_orders as is\n",
    "df_joined = df_orders.join(df_customers_sorted, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "df_joined.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b8bc7ee-d6f1-4184-9ab8-6b1add6541de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bucketed_customers = spark.table(\"bucketed_customers\")\n",
    "bucketed_orders = spark.table(\"bucketed_orders\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03622e16-4e98-4e18-b027-7c3b362d0c65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Steps to create and manage Delta tables with optimized schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ab71aec-4a17-44b2-99c8-40b556e7eb36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "\n",
    "customer_schema = StructType([\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"customer_unique_id\", StringType(), True),\n",
    "    StructField(\"customer_zip_code_prefix\", StringType(), True),\n",
    "    StructField(\"customer_city\", StringType(), True),\n",
    "    StructField(\"customer_state\", StringType(), True),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5254a3d1-5a87-431f-90cf-1d5001f45bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read customers CSV with predefined schema\n",
    "df_customers = spark.read.schema(customer_schema) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(\"dbfs:/Volumes/commerce_spark_workspace/default/ecommerce_raw/olist_customers_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "239fd974-5fe4-48d3-958e-75496b4bf547",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_customers.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"customer_state\") \\\n",
    "    .saveAsTable(\"delta_olist_customers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc270832-6604-4855-938f-d583dd59915b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------------+-------------+--------------+\n|         customer_id|  customer_unique_id|customer_zip_code_prefix|customer_city|customer_state|\n+--------------------+--------------------+------------------------+-------------+--------------+\n|4fa19f7da692e6bf9...|a2b8841410cf77619...|                   72270|     brasilia|            DF|\n|e50a30de3c32f9406...|b4d6e1b900d99b52e...|                   71540|     brasilia|            DF|\n|9b7822c67a91b431e...|9d0ac1cdbfc919d67...|                   71928|     brasilia|            DF|\n|8b47e5ba29a9cd994...|9bbfdf9f7f65b5848...|                   71665|     brasilia|            DF|\n|d6ea00d4a2dca6a01...|1d4626b197f66aa61...|                   73020|     brasilia|            DF|\n+--------------------+--------------------+------------------------+-------------+--------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Optimize the Delta table for better query performance\n",
    "spark.sql(\"OPTIMIZE delta_olist_customers ZORDER BY (customer_city)\")\n",
    "\n",
    "# Read and display sample data from the Delta table\n",
    "df = spark.read.format(\"delta\").table(\"delta_olist_customers\")\n",
    "df.show(5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark Configuration and Optimization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}